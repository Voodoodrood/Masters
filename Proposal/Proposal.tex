\documentclass{sig-alternate-05-2015}
\usepackage{float}
\usepackage{enumitem}
\usepackage{subfiles}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{tabularx}

\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\begin{document}
\title{A user interface for landscape modelling in a virtual environment using a head mounted display}

\numberofauthors{1}
\author{
\alignauthor
Timothy Gwynn\\
       \affaddr{GWYTIM001}\\
       \affaddr{University of Cape Town}
}
\maketitle
\begin{CCSXML}

\end{CCSXML}



\printccsdesc
\keywords{Virtual Environments, Terrain Synthesis, User Testing}
\begin{abstract}
	
\end{abstract}
\section{Introduction}
\section{Background Reading}
\subsection{Terrain Synthesis}
\subsection{Interface design for modelling in large-scale Virtual environments}
Somewhere need to talk about camera control, not sure where cite ware and bowman
\subsubsection{Navigation in Virtual Environments}
There are a number of studies analyzing techniques for user navigation and viewpoint control in VEs.

Bowman et al. have created a list of aims for effective travel techniques.\cite{Bowman1997} These include, speed, accuracy, spatial awareness, ease of learning, ease of use, information gathering and presence. We suggest that user comfort should also be taken into account especially when designing a VE interface for 6DOF controllers.

 In the same paper Bowman et al. present a categorization of travel techniques\cite{Bowman1997}. This allows us to categorize a number of techniques into two broad categories: Gaze directed steering and gesture directed steering. Gaze directed steering refers to instances where the user's navigation is controlled via a tracked HMD while gesture directed  steering involves the user controlling their direction of movement through gestures (with or without props). Bowman et al. then performed a series of experiments where they found that tool directed navigation was faster than gaze directed navigation for navigating relative to objects and equal for navigating to an absolute point in space. Additionally since gesture directed steering allows the user to freely observe their environment during travel it allows for superior spatial awareness and information gathering. We therefore suggest that we should prefer gesture directed steering techniques.

Other areas of research related to navigation include investigation into the effectiveness of various types of landmarks. These include a study of whether users orientate themselves via local or global landmarks\cite{Steck2000}. Steck et al. found that although users would alternate between using local and global landmarks in certain situations they tended not to combine them. They suggest that users will tend to use the most visually distinct land marks and will prefer to use landmarks that are not occluded. This implies that navigation interface design should provide a variety of landmarks, both global and local, that allow the user to always have a distinctive point of reference. It also suggests that global landmarks that will not be occluded by local geometry should be used. A good example of this would be a static sun-like object in the sky.

Vinson et al. performed further research into the design of landmarks for VEs.\cite{Vinson1999} They found that users tend to use landmarks that resemble manmade artifacts in natural environments. Additionally they suggest that landmarks should all be orientated the same way and marked accoriding to this orientation. This allows the user to extract orientation information as well as location information from a single landmark.

Darken et al. compared a variety of tools for navigation in virtual environments including landmarks, breadcrumb markers and map views amongst others\cite{Darken1993}. They associated their techniques with natural human and avian  navigational behaviours. While they did not evaluate the effectiveness of the different techniques they did detail the common behaviour of the test subjects for each technique. By observing which techniques lead to simple or complex behaviour we can surmise which techniques are effective from at least an ease of use perspective. They found that the map view in particular allowed for very simple behaviour although they suggested that this was linked to the navigation space being a 2D plane. Users also were able to follow a simple sequence of actions in a scenario where they were able to fly vertically which let them observe the navigational space from above at a distant perspective. They also found that while landmarks were effective for distinguishing certain areas they provided little directional information. When they added a synthetic sun in the test case with landmarks which provided orientation information user performance increased significantly.

Darken et al.'s experiments reinforce the concept of a combination of local and global landmarks being useful for navigation.\cite{Darken1993} Additionally, the ease of use of both the map and the flying technique suggest that allowing the user to move in 3 dimensions and providing a 3D map will aid navigation considerably. 
\subsubsection{Interface interaction in VEs}
 Interaction with the interface refers to the user modifying the state of the system or the mode of interaction\cite{Bowman2001}. Typical examples include menu interaction and tool selection. These tasks, which are often 2D or 1D are ill suited to 3D environments\cite{Bowman2001, Hand1997}.
 
 Hand et al. also observe that directly converting 2D interface elements to a stereoscopic system can cause difficulties.\cite{Hand1997} Particularly, the increased dimensionality of the task can lead to a significantly higher error rate and issues of occlusion need to be taken into account.
 
 Hand et al. suggest a "ring menu" as a way to implement 1 dimensional interface interactions that allow users to navigate menus or select tools.\cite{Hand1997} Some alternatives to menu interaction at all include gesture based shortcuts such as those used by Zeleznik et al.\cite{Zeleznik2007} or speech input as suggested by multiple papers. \cite{VanDam1997,Bowman2001,Hand1997} An interesting combination of the gesture based shortcuts and radial menu concepts is letting users utilize miuscle memory to select tools from the radial menu without actually displaying it.\cite{Kurtenbach1993}
 
 The issue of "clutching", where a user must pause movement tracking so as to reset to a comfortable position without interfering with the current interaction is also mentioned in Hand et al.'s paper.\cite{Hand1997} An example of this is when a user desires to rotate an object further than is comfortable with a single movement. It is suggested that utilizing direct mapping of controls onto virtual objects combined with THI can reduce or remove the need for this.\cite{Hand1997}  Hinckley et al. suggest that utilizing THI can reduce the need for clutching by tracking gestures of the dominant hand relative to those of the non-dominant hand.\cite{Hinckley1994} They also suggest that an alternative is to use a physical 3D prop such as those used by [find paper where world in minature is used with camera prop]
 
 One more aspect of interface inteaction design that has been explored is the positioning of interface elements.\cite{alger2015visual} Here we need to avoid issues where the interface is too close to the user so that it is hard to focus on. However, interface elements must not be out of comfortable reach. These constraints combine to leave a relatively restricted area in which we can place interface elements.
 
 [Talk about visualizing physical enviroment or aspects therof] 
 
 Mine et al. created custom 3D controllers using a combination of touch screens and physical buttons.\cite{Mine2014} These were well suited for menu selections as the 2D touch surface mapped directly to 2D interface elements. From this we can surmise that finding an alternative to motion tracking for interface interaction is advisable. [Can either discuss other specific techniques for interface interaction here or move it to related work]
 
 
\subsubsection{Environment interaction in VEs}
What to put here: [Widget design and interaction(go go hand, raycasting), painting and sketching, user comfort in design, cursors or intersection lines, depth issues, trying to handle 2D objects or points, natural design, audio notes]


 Interaction with environment involves the user making changes to the virtual environment through selection and manipulation of objects. To do this users should, at minimum, be able to either select or position or rotate objects\cite{Bowman2001}. Research in this area addresses both the wide range of hardware devices created for interacting the VEs as well as the related software solutions. Common tools include a motion tracked glove \cite{Zimmerman1986} and pen or wand controllers.\cite{Schultheis2012}
 
 There have also been a number of investigations into the advantages of THIs over other interaction methods. It is widely agreed that humans are better able to judge relative position of their hands than absolute position.\cite{Bowman1998, Buxton1986} Additionally users have a preference for THI\cite{Buxton1986} and perform certain basic manipulation tasks such as rotaion and translation more efficiently when using two hands.\cite{Schultheis2012} Therefore interfaces should be designed for bi-manual interaction and motion should be tracked with the dominant hand relative to the non-dominant hand.\cite{Hinckley1994}
 
 Another area of interest in Environment interaction is how to interaction with objects far away from the user. This is commonly refered to as action at a distance (AAAD). Techniques to address this include the go-go hand technique\cite{Poupyrev1996}, where the hand is tracked and then non-linearly mapped into the VE and a number of raycasting techniques discussed by Bowman et al.\cite{Bowman2001}. These methods roughly correspond to the function of a cursor in a 2D environment. Hand et al. suggest that although cursors are a necassary metaphor in a 2D environment they do not correspond well enough with natural gestures for use in VEs.\cite{Hand1997}
 
 Although there are a number of ways to perform AAAD users also need depth cues to manipulate or select objects with precision.\cite{Schultheis2012} Some suggested methods for this include representing the user's hand as a transparent outline in the VE\cite{Hinckley1994} or drawing a line between the user's hands in the VE.\cite{Schultheis2012}
 
 
 Studies also suggest that degrees of freedom (DOF) should be restricted as much as possible to simplify interaction with the VE.\cite{Bowman2001}
 
 
  With regards to the software solutions a number of 3D widgets haven been implemented and tested [examples and citations here].
 

\subsection{Usability testing}
\section{Related Work}
\subsection{Comparison of Desktop applications to Virtual environment}
\subsection{Designing for Virtual Environments in Virtual Environments}
\section{Research question(s)}
\section{Method}
\subsection{System Design}
\subsection{Experimental design}
\subsection{Data collection}
\subsection{Data analysis}
\section{Project plan}
\subsection{Requirements}
\subsection{Risks}
\subsection{Timeline}
\section{Research outcomes}
\subsection{Artifacts produced}
\subsection{Success factors}
\subsection{Relevance to industry}
\subsection{Further research}

\bibliographystyle{abbrv}
\bibliography{proposal}
\end{document}