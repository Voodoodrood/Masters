\documentclass{sig-alternate-05-2015}
\usepackage{float}
\usepackage{enumitem}
\usepackage{subfiles}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{tabularx}
\usepackage{url}
\usepackage{xcolor}
\usepackage{soul}

\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\begin{document}
\title{A user interface for landscape modelling in a VE using a head mounted display}

\numberofauthors{1}
\author{
\alignauthor
Timothy Gwynn\\
       \affaddr{GWYTIM001}\\
       \affaddr{University of Cape Town}
}
\maketitle
\begin{CCSXML}

\end{CCSXML}



\printccsdesc
\keywords{Virtual Environments, Terrain Synthesis, User Testing}
\begin{abstract}
	
\end{abstract}
\section{Introduction}
Landscape modelling is a method for creating realistic virtual landscapes. It allows the designer to set constraints in order to shape the terrain as desired. Based on the constraints set by the user the synthesis application will then attempt to create a realistic terrain. In this way the designer can create terrain with specific global and local features without manually drawing everything. Virtual terrains are used as components for natural environments in computer games, film, simulation and training\cite{Gain2015}

Virtual environments(VEs) describe a set of three dimensional visual output technologies. These technologies aim to embed users visually within virtual worlds much as technologies such as surround sound or headphones do via audio. Examples of these technologies include CAVE (CAVE Automatic Virtual
Environment)  systems and HMD (head mounted display) devices.
CAVE devices surround the user with a number of large screens as well as tracking user head position\cite{Cruz-Neira1993} This provides the visual equivalent of surround sound. HMD devices fit over the user's face and the device itself is tracked and can be described as headphones for your eyes.\cite{alger2015visual}

VE technologies are also often associated with novel input devices such as 6 degree of freedom(DOF) devices which allow users to provide 3 dimensions of positional input and 3 dimensions of rotational input. Thanks to the continuing research into this technology there are a wide range of such devices. Unlike traditional WIMP interfaces where almost every system is designed for a mouse and keyboard VE systems tend to rely on specialized input devices\cite{Hand1997,Bowman2001}. However, with the recent increase in consumer access to commercial devices such as the Oculus Rift and Vive that come with generic controllers for use with multiple games and applications this may be changing.

Creating effective user interfaces for VE technology, especially for the design process allows us to take full advantage of this new technology. Post-WIMP interfaces promise a radical change in the way we interact with software applications and, if implemented well, could result in greatly increased productivity and control using VEs.
 
 By creating systems for designers to perform landscape modelling for VEs from within VEs we allow them to better understand and design for the end user experience. Additionally, we hope to provide a design environment that is more efficient than a desktop system for experienced users. Due to the association of increased immersion and flow in VEs compared to desktops \hl{[need citation]} we also hope to encourage these phenomena in the design environment.
\section{Background}
There are large bodies of work on both interactive terrain synthesis and VE interface design. It should be noted that work related to terrain synthesis tends to focus on synthesis techniques rather than the interface. Additionally, as suggested in the introduction much of the work on VE interfaces has been done using custom or specialized controllers and other hardware. Earlier works in particular discuss issues such as motion sickness which modern hardware has largely solved. Here we will discuss the more relevant aspects of previous works related to our research. We detail current solutions to interactive terrain synthesis and a range of interface design techniques for VEs. We also cover work that has shown that certain tasks can be accomplished more quickly in VEs than on desktop systems. This provides one of our primary motivations for our research. Finally, we discuss previous systems that were designed to do similar VE modelling tasks. 
\subsection{Terrain Synthesis} 
Virtual landscapes are an important component in representing natural environments for applications such as computer games, film, simulation and training\cite{Gain2015}. Fast and realistic terrain synthesis has been the subject of considerable study with a variety of techniques such as patch or texture based synthesis\cite{Cruz2015, Tasse2012}, noise based synthesis\cite{Musgrave1989} and erosion simulation\cite{Anh2007}. With advances in graphics processing technology we are able to simulate terrain that is indistinguishable from real terrain examples\cite{Gain2015}. 

 Gain et al.'s terrain synthesis system allows users to introduce constraints into the terrain synthesis process using a number of tools\cite{Gain2015}. The ability to add and modify geometric constraint points and curves to a landscape allows users to create landscape features such as hills, ridges and valleys.  Coherence controls allow users to fix parts of the landscape preventing later changes elsewhere from affecting it. Copy/paste functionality allows landscape regions to be moved to new locations and elevations. Type constraints which can be painted onto the landscape to define areas of a certain type such as 'swamp', 'dirt' etc. To interact with these tools users have access to a combination of sketching, painting and 3D widget interface elements. %As this software will form the basis for the application being created in this study we will need to reproduce and modify these tools for use in VEs.

Tasse et al.'s paper on first person terrain editing presents a sketch based technique which allows users to  edit terrain from a single point of view\cite{Tasse2014}. Although there is focus on editing the terrain from a FPV in the application, the users requested the ability to have a separate viewpoint from which to see their changes made in the FPV. In the paper itself we are regularly given a top view to display how the changes affected the terrain as a whole. This reinforces the need to give users both an immersive FPV and a remote top-view.
\subsection{Interface design for modelling in large-scale Virtual environments}
\hl{Somewhere need to talk about camera control, not sure where cite ware and bowman}
\subsubsection{Navigation in Virtual Environments}
\hl{Need to motivate why navigation is hard and needs consideration}
There are a number of studies analysing techniques for user navigation and viewpoint control in VEs.

Bowman et al. have created a list of aims for effective travel techniques.\cite{Bowman1997} These include, speed, accuracy, spatial awareness, ease of learning, ease of use, information gathering and presence. We suggest that user comfort should also be taken into account especially when designing a VE interface for 6-DOF controllers.

 In the same paper Bowman et al. present a categorization of travel techniques\cite{Bowman1997}. This allows us to categorize a number of techniques into two broad categories: Gaze directed steering and gesture directed steering. Gaze directed steering refers to instances where the user's navigation is controlled via a tracked HMD while gesture directed  steering involves the user controlling their direction of movement through gestures (with or without props). Bowman et al. then performed a series of experiments where they found that tool directed navigation was faster than gaze directed navigation for navigating relative to objects and equal for navigating to an absolute point in space. Additionally since gesture directed steering allows the user to freely observe their environment during travel it allows for superior spatial awareness and information gathering. We therefore suggest that we should prefer gesture directed steering techniques.

Other areas of research related to navigation include investigation into the effectiveness of various types of landmarks. These include a study of whether users orientate themselves via local or global landmarks\cite{Steck2000}. Steck et al. found that although users would alternate between using local and global landmarks in certain situations they tended not to combine them. They suggest that users will tend to use the most visually distinct land marks and will prefer to use landmarks that are not occluded. This implies that for navigation, interface design should provide a variety of landmarks, both global and local, that allow the user to always have a distinctive point of reference. It also suggests that global landmarks that will not be occluded by local geometry should be used. A good example of this would be a static sun-like object in the sky.

Vinson et al. performed further research into the design of landmarks for VEs.\cite{Vinson1999} They found that users tend to use landmarks that resemble man-made artefacts in natural environments. Additionally they suggest that landmarks should all be orientated the same way and marked according to this orientation. This allows the user to extract orientation information as well as location information from a single landmark.

Darken et al. compared a variety of tools for navigation in VEs including landmarks, breadcrumb markers and maps amongst others\cite{Darken1993}. They associated their techniques with natural human and avian  navigational behaviours. While they did not evaluate the effectiveness of the different techniques they did detail the common behaviour of the test subjects for each technique. By observing which techniques lead to simple or complex behaviour we can surmise which techniques are effective from an ease of use perspective. They found that the map view in particular allowed for very simple behaviour although they suggested that this was linked to the navigation space being a 2D plane. Users also were able to follow a simple sequence of actions in a scenario where they were able to fly vertically which let them observe the navigational space from above at a distant perspective. They also found that while landmarks were effective for distinguishing certain areas they provided little directional information. When they added a synthetic sun in the test case with landmarks which provided orientation information user performance increased significantly.

Darken et al.'s experiments reinforce the concept of a combination of local and global landmarks being useful for navigation.\cite{Darken1993} Additionally, the ease of use of both the map and the flying technique suggest that allowing the user to move in 3 dimensions and providing a 3D map will aid navigation considerably. 
\subsubsection{Interface interaction in VEs}
 Interaction with the interface refers to the user modifying the state of the system or the mode of interaction\cite{Bowman2001}. Typical examples include menu interaction and tool selection. These tasks, which are often 2D or 1D are ill suited to 3D environments\cite{Bowman2001, Hand1997}.
 
 Hand et al. also observe that directly converting 2D interface elements to a stereoscopic system can cause difficulties.\cite{Hand1997} Particularly, the increased dimensionality of the task can lead to a significantly higher error rate and issues of occlusion need to be taken into account.
 
 Hand et al. suggest a "ring menu" as a way to implement 1 dimensional interface interactions that allow users to navigate menus or select tools.\cite{Hand1997} Some alternatives to menu interaction at all include gesture based shortcuts such as those used by Zeleznik et al.\cite{Zeleznik2007} or speech input as suggested by multiple papers. \cite{VanDam1997,Bowman2001,Hand1997} An interesting combination of the gesture based shortcuts and radial menu concepts is letting users utilize miuscle memory to select tools from the radial menu without actually displaying it.\cite{Kurtenbach1993}
 
 The issue of "clutching", where a user must pause movement tracking so as to reset to a comfortable position without interfering with the current interaction is also mentioned in Hand et al.'s paper.\cite{Hand1997} An example of this is when a user desires to rotate an object further than is comfortable with a single movement. It is suggested that utilizing direct mapping of controls onto virtual objects combined with THI can reduce or remove the need for this.\cite{Hand1997}  Hinckley et al. suggest that utilizing THI can reduce the need for clutching by tracking gestures of the dominant hand relative to those of the non-dominant hand.\cite{Hinckley1994} They also suggest that an alternative is to use a physical 3D prop such as those used by \hl{[find paper where world in miniature is used with camera prop]}
 
 One more aspect of interface interaction design that has been explored is the positioning of interface elements.\cite{alger2015visual} Here we need to avoid issues where the interface is too close to the user so that it is hard to focus on or where interface elements are out of comfortable reach. These constraints combine to leave a somewhat restricted area in which we can place interface elements.
 
 \hl{[Talk about visualizing physical enviroment or aspects therof]}
 
 Mine et al. created custom 3D controllers using a combination of touch screens and physical buttons.\cite{Mine2014} These were well suited for menu selections as the 2D touch surface mapped directly to 2D interface elements. From this we can surmise that finding an alternative to motion tracking for interface interaction is advisable. \hl{[Can either discuss other specific techniques for interface interaction here or move it to related work]}
 
 
\subsubsection{Environment interaction in VEs}
 Interaction with environment involves the user making changes to the virtual world through selection and manipulation of objects. To do this users should, at minimum, be able to either select or position or rotate objects\cite{Bowman2001}. Research in this area addresses both the wide range of hardware devices created for interacting the VEs as well as the related software solutions. Common tools include a motion tracked glove \cite{Zimmerman1986} and pen or wand controllers\cite{Schultheis2012}. 
 There have also been a number of investigations into the advantages of two-handed-interfaces(THI) over other interaction methods. It is widely agreed that humans are better able to judge relative position of their hands than absolute position.\cite{Bowman1998, Buxton1986} Additionally users have a preference for THI\cite{Buxton1986} and perform certain basic manipulation tasks such as rotation and translation more efficiently when using two hands\cite{Schultheis2012,Balakrishnan1999}. Therefore interfaces should be designed for bi-manual interaction and motion should be tracked with the dominant hand(DH) relative to the non-dominant hand (NDH)\cite{Hinckley1994}.
 
 Another area of interest in Environment interaction is how to interaction with objects far away from the user. This is commonly referred to as action at a distance (AAAD). Techniques to address this include the go-go hand technique\cite{Poupyrev1996}, where the hand is tracked and then non-linearly mapped into the VE and a number of ray-casting techniques discussed by Bowman et al.\cite{Bowman2001}. These methods roughly correspond to the function of a cursor in a 2D environment. Hand et al. suggest that although cursors are a necessary metaphor in a 2D environment they do not correspond well enough with natural gestures for use in VEs\cite{Hand1997}.
 
 Although there are a number of ways to perform AAAD users also need depth cues to manipulate or select objects with precision.\cite{Schultheis2012} Some suggested methods for this include representing the user's hand as a transparent outline in the VE\cite{Hinckley1994} or drawing a line between the user's hands in the VE.\cite{Schultheis2012}
 
 
 Studies also suggest that degrees of freedom (DOF) should be restricted as much as possible to simplify interaction with the VE.\cite{Bowman2001}
 
 
  With regards to the software solutions a number of 3D widgets haven been implemented and tested \hl{[examples and citations here].}
 


\subsection{Comparison of Desktop applications to Virtual environment}
There have been a number of studies comparing user performance in VEs and desktop environments. In studies where users had to perform simple tasks expert users completed the tasks up to 8 times faster in the VE than on a desktop.\cite{Schultheis2012} However, in more complex applications, especially where indoor navigation was required or training time was low, users tended to perform better on desktop systems\cite{SousaSantos2009}. However, even in systems where users were novices they felt that the VE interfaces were more intuitive and easier to use\cite{Toma2012}.

 Scali et al. performed an experiment comparing a traditional WIMP interface to a number of VE set-ups with 6-DOF controllers that varied stereo-vision, haptic feedback and a snapping tool\cite{Scali2003}. They found that the VE systems outperformed the WIMP interfaces with regards to time for task completion, perceived workload and usability. Additionally they found that although haptics and stereo vision did not significantly affect task completion times haptics had a significant effect on perceived workload and usability.
 
 \hl{To add: go into more detail on each experiment, find some more}
\subsection{Designing for Virtual Environments in Virtual Environments}
There a large variety of systems that have been developed to study methods of modelling 3D objects and environments in VEs. These systems use a variety of devices and techniques to overcome some of the common problems with VE design such as menu interaction.

A common technique for supporting menu interaction is to take advantage of users innate knowledge of the relative positions of their hands\cite{Bowman1998, Buxton1986}. To do this systems are designed such that the menu is attached to the user's NDH either as a physical touch screen\cite{Wang2013,Mine2014} or as a virtual representation\cite{Jerald2013}

Another result from previous experiments is that being able to bring the geometry to the user provides an experience with very few fatigue issues\cite{Jerald2013}. Fatigue is something we need to keep in mind when designing the system as Song et al. found when trying to implement a handle bar metaphor for visual control\cite{Song2012}.

The problem of inputting text for VE environments while using 6-DOF devices is certainly one of the more pressing issues for the technology. A number of systems incorporate an aspect of voice input to make up for this loss\cite{Ponto2013,Toma2012}. Of particular interest is a method used in the system "Placeholder" created by Laurel et al. that allowed users to create audio notes at certain locations that could be recorded and then played back at any time\cite{Laurel1994}.

Mine et al. make a number of suggestions on how to effectively map certain actions in the virtual world to two hand controllers\cite{Mine2014}. Although they used custom controllers some of the concepts are general enough to carry over to a range of THI. Particularly they suggest keeping the functions of each hand relatively independent such that users do not have to use both controllers at once. This seems to contradict what a number of studies that have shown that users are capable of and in fact tend to use two hands when able to\cite{Buxton1986,Hinckley1994}. What separating the tasks may have done in Mine et al.'s experiment is allow users to simultaneously perform two independent tasks.  Mine et al. also suggest having a small number of buttons dedicated to essential tasks that are performed often\cite{Mine2014}.
\section{Research question(s)}
The primary purpose of this research is to establish whether using a VE interface is advantageous over using a desktop interface to interactively model terrain for use in VE applications.

This research potentially allows us to recommend effective VE interface design techniques for 3D design. Additionally, we may be able to conclude that the relatively new HMD technology is useful for content creation as well as consumption in the area of 3D design. We will determine whether HMD and 6-DOF controller interfaces are faster, more accurate or provide greater usability when compared to traditional WIMP(windows, icons, menus, pointer) interfaces. Finally we will be able to determine if being immersed in a VE helps designers create user experiences that are consistently closer to their design concept.

The primary research question is therefore: \textit{Is it advantageous to use a VE interface with a HMD and 6-DOF controllers over a WIMP desktop interface?}
Where we define advantageous as faster, more accurate, more usable or more expressive. These aspects can be measured and compared independently to one another and therefore we can form four sub-questions.
\subsection{Modelling time}
This refers to the time it takes for a designer to create a terrain using a given system. Although simple to measure, it is somewhat difficult to establish when a design is finished. Our technique for determining this factor will be elaborated on below. Our research question is therefore:\\
\textbf{Is it faster to create a model that the user feels is complete in a VE or using a desktop?}\\
\begin{description}
	\item [H$_{A0}$] There is no difference in time taken to create a complete model to the user's satisfaction in a VE than using a desktop.
	\item [H$_{A1}$] Less time  is taken to create a complete model to the user's satisfaction in a VE than using a desktop.
	\item [H$_{A2}$] More time  is taken to create a complete model to the user's satisfaction in a VE than using a desktop.
\end{description}
\subsection{Modelling Accuracy}
We define accuracy as closeness to a concept image. In order to measure this for experimentation we will give users a image of an existing terrain to try copy. In reality however the image will be from the designers mental concept. Because of this we will be measuring conceptual similarity, by using an independent subjective measure, rather than physical similarity which would be measured by computing volume differences. our research question is therefore:\\
\textbf{Are terrains models created in a VE visually closer to a target terrain image than those created with a desktop system?}\\
\begin{description}
	\item [H$_{B0}$] There is no difference in similarity between terrains created in a VE or using a desktop.
	\item [H$_{B1}$] Terrains created in a VE are more similar than those created on a desktop system.
	\item [H$_{B2}$] Terrains created in a VE are less similar than those created on a desktop system.
\end{description}
\subsection{Usability}
Usability refers to how easy a system is to use for its intended purpose. This can be broken down further into how easy it is to learn, the cognitive load on the user, the physical strain on the user and time taken to complete basic tasks. There is a substantial body of research on defining and measuring usability and we will utilize this to determine a suitable scale to measure usability. With regards to usability our research question is:\\
\textbf{Do users rate the usability of the VE system more highly than that of the desktop system?}\\ 
\begin{description}
	\item [H$_{C0}$] There is no difference in usability between the VE system or the desktop system.
	\item [H$_{C1}$] The VE system has higher usability than the desktop system.
	\item [H$_{C2}$] The VE system has lower usability than the desktop system.
\end{description}
\subsection{User Expression}
This refers to the ability of a user to express his or her mental image in the virtual medium. We feel that the immersive aspect of the VE system coupled with the ability to switch to a FPV will enable users to create terrains express their concepts more faithfully. This is somewhat related to accuracy and usability but is perhaps a more subjective measure than either of these. Our research question regarding user expression is: \\
\textbf{Do users feel more able to express their concept using the VE system or the desktop system?}\\
\begin{description}
	\item [H$_{C0}$] There is no difference in user expression between the VE system or the desktop system.
	\item [H$_{C1}$] Users feel they can express their concept better using the VE system.
	\item [H$_{C2}$] Users feel they can express their concept better using the desktop system.
	
\hl{[note: this is somewhat a wish list aspect of the research will probably need to be dropped due to being rather vague]}
\end{description}
\section{Method}
In order to establish the answers to the research questions above we will implement a VE application based on Gain et al.'s terrain synthesis application\cite{Gain2015}. This application will use the same terrain synthesis methods but will incorporate a new interface that has been re-designed for use in a VE. We will then be able to compare how users perform on the existing desktop system against performance using the VE system. This will allow us to determine which system performs better on a number of measures detailed later.
\subsection{System Design}
\subsubsection{Hardware and Software requirements}
The system will use a HMD device together with two 6-DOF controllers to provide output and allow for user input.The user will interact with the system using only these devices. The system will be designed such that it can be used while seated at a desk. This will help reduce user fatigue\cite{Schultheis2012}. There will also need to be real-time or close to real-time feedback based on users input as the existing desktop system currently does.

The interface will be created using Unity 3D for Linux while the back-end software from the existing desktop system will remain unchanged unless absolutely necessary. It will be necessary for the VE interface to communicate with the back-end of the existing system, this may be a significant challenge requiring custom software.

\subsubsection{User-System interaction}
The design will be based on the findings of previous work in the area of designing for VEs in VEs. This will lead to a VE system that is optimized for both work flow speed and usability as well as user experience. We will aim to maximise user comfort while allowing for terrain modelling to be done quickly and accurately.

The system will feature controls that allow for the sketching, painting and widget manipulation present in the existing desktop system. We will be able to implement each of these features independently although the system will need the sketching and widget manipulation features at a minimum to function meaningfully. These controls allow the user to set constraints on the terrain that the automatic synthesis must conform to. For example, the user may sketch a line across the surface of the terrain and then raise that line using 3D widgets to create a ridge. 

We will provide a radial menu system that the user can navigate using either the joysticks on the controllers or through gesture recognition. This will allow the user to chose which tool to use or to access a menu for saving the current design or loading an existing terrain. New users will be able to bring the menu up with a button press and then navigate using the joystick. More experienced users will simply tap the button and follow that with a quick gesture in the correct direction to select a tool without actually displaying the menu.

We will also need to implement at least one method for user navigation and camera control such that designers can view and interact with the environment. Ideally we hope that the designer will be able to switch between a first person viewing (FPV) mode where they are able to move over the landscape and a remote mode with a top down view where the entire terrain or large sections thereof will be visible. In FPV mode designers will be able to experience their terrains from the end user perspective. Additionally, they will be able to modify the terrain somewhat in this mode using a tool such as the go-go hand. In remote mode designers will more easily be able to modify the terrain constraints. By being able to see a large part of the terrain designers can easily see how their changes affect the model as a whole and the relative size of various features.


\subsection{Experimental design}
The experiment will be single blind, between groups design. Users will not know the other condition but will know what is being measured(speed, accuracy etc.). We will need two groups of users to perform the experiment. The control group will use the existing desktop system while the experimental group will use the VE system. Participants will be selected via convenience sampling. Users are unlikely to have had VE experience. Computer science students are likely to make up the majority of these users. As such most users will have experience with traditional WIMP interfaces. Additionally, it is likely that a number of users will have experience using 3D modelling tools on desktop systems. We will need to balance the groups for experience with 3D modelling related tools as well as experience with 3D applications in general.

Each group will attend two sessions. During the first session both groups will perform a series of training exercises. It has been shown that training has a significant effect on user performance in VEs\cite{Schultheis2012}. During this session users will be able to familiarise themselves with the system they are using. This will also compensate, somewhat, the difference in experience among users who have used similar systems before. The second session will occur a short number of days later. This will prevent the effectiveness of the training sessions from fading significantly. The two sessions will not occur immediately after one another to prevent fatigue from training with unfamiliar systems from affecting the results of the experiment.

During the second session each group will be asked to perform the same terrain modelling tasks such as replicating an existing terrain as closely as possible. Users will be monitored for speed and accuracy. Additionally, the experiments will be followed by questionnaires regarding the usability of the system as well as questions related to VE issues such as fatigue, motion sickness and disorientation.

Our independent variable will be the system used (Desktop or VE) and our independent variables will be speed, accuracy and user satisfaction/ usability.

\hl{[To Add: More detail on tasks to perform, Look into research on usability testing to support or change these design decisions, mention users will be seated?]}
\subsection{Data collection}
During the experiment we will have a telemetry system running in the background that will provide detailed information on user inputs and actions. We will also be recording the time it takes users to complete each modelling task. After all tasks have been completed we will then collect usability feedback via questionnaire.
\hl{[To add: consider think out loud feedback]}
\subsection{Data analysis}
Time to complete the modelling tasks will be compared using statistical measures.

Accuracy will be somewhat more complex to measure. It would be possible to simply compare the volumes of the example terrain to the modelled terrain and extract the difference as a percentage of the total original volume. However, during an actual design process designers are likely to have a certain concept scene in mind and will be more concerned with producing that as accurately as possible rather than filling a specific volume. It therefore seems sensible to use a board with members familiar with terrain modelling or design which will judge the similarity of the modelled terrain to the given example. This will allow for subjective feedback that more closely resembles the way in which designers will try to actualize a mental image in virtual reality.

We will use the Post-Study System Usability Questionnaire (PSSUQ) which is a 19-item, 7 point scale questionnaire\cite{Lewis1995} to measure the usability of our system. The PSSUQ will allow us to collect results on overall satisfaction, system usefulness, information quality and interface quality.

\hl{[To add: What additional data will be collected/ analysed, consider flow and common VR issues from ED]}

\section{Project plan}
\subsection{Requirements}
\subsubsection{Hardware}
We will need to provide users with a VE experience that can be used in a typical environment of 3D content designers. As CAVE systems have both a high cost and require a large space it is impractical to use these as an everyday tool particularly if multiple designers need to be working at once. HMDs provide a much more compact solution allowing users to work while sitting in a typical workspace area with a desk and chair. We therefore will be using a HMD device with two 6-DOF controllers for the VE system. Due to the availability, recent popularity and the integration with existing developer tools of the Oculus Rift headset we will be using this as our HMD device. Additionally Oculus has released 6-DOF controllers known as Oculus touch controllers that are designed to be used with their headset\cite{Oculus}. We will therefore be using a pair of these controllers. The Oculus HMD device requires a workstation with sufficient capabilities. According to Oculus the minimum requirements for their device are\cite{Oculus}:
\begin{itemize}
\item Video Card:  NVIDIA GTX 970
\item CPU: Intel i5-4590
\item Memory:  8GB+ RAM
\item Video Output:  free HDMI 1.3 output
\item USB Ports:  3x USB 3.0 ports plus 1x USB 2.0 port
\item OS: Windows 10 64 bit
\end{itemize}
\subsubsection{Software}
The system will rely on the software created for the terrain synthesis paper by Gain et el.\cite{Gain2015}. This will provide the terrain synthesis functionality and will also be used as the desktop system to which the VE system is compared. To do this we can compile a significant portion of the existing software to .dll files which can then be accessed through C\# in Unity. 

The VE interface will be built using Unity3D for Linux. Unity3D has built in support for the Oculus Rift as well as the Oculus touch controllers. Additionally the researcher has prior experience with the Unity3D system. This will reduce the time taken to create the VE system as there will be no need for the researcher to familiarize himself with a new platform.

\subsubsection{People}
A small group of individuals will be needed to perform pilot tests to guide the creation of the VE interface. These individuals will likely be experienced with system design and computer interfaces and may be familiar with HMD devices.

A significantly larger group will be needed to carry out the final experiment. This group should have some experience with computer interfaces and preferably some experience with 3D modelling tools such as Unity etc. Additionally we will not be able to have test subjects that have significant vision or motor control impairments.

Finally we will need a small group of individuals familiar with terrain design in order to analyse the accuracy of the terrain models created during the experiment. 
\subsection{Risks}
\hl{[Create Risk table]}\\ Principle risks are:\\
Can't get unity/UTS to communicate\\
Can't get UTS to run in real time on Oculus\\
Unable to implement certain required functionalities for the VE interface\\
Unavailability of test subjects
\subsection{Timeline}
\hl{[Make a gant chart]}
\section{Research outcomes}
\subsection{Artefacts produced}
During the course of this research a VE interface system designed for the Oculus rift and Oculus touch controllers will be produced. This will interact with the terrain synthesis functionality of the existing UTS desktop system\cite{Gain2015}. The resulting application will provide an immersive user experience that allows for terrain modelling and synthesis in a VE.
\subsection{Success factors}
It is expected that the VE interface will allow users to model terrains with statistically significant lower times due to the ability to work in more than one dimension at a time. We also expect that the VE interface will provide a more natural method of interacting with the terrain model and will therefore be given a statistically significant higher usability rating. Due to the greater speed and more natural method of interaction we expect that users will be able to make more adjustments to their design resulting in designs that are more accurate by a statistically significant margin. By immersing designers in a VE we expect that they will gain a more realistic idea of the user experience allowing them to create designs closer to their mental concepts.

If these expectations are shown to be true we will be able to conclude that, in some ways at least, VE systems are advantageous to desktop interfaces for terrain modelling. 
\subsection{Relevance to industry}
Should this research show that designing in VEs is viable and even advantageous especially when deigning for VE experiences it may support a move away from desktop workstations in the workplace. Additionally, although out of the scope of this project, VE interfaces may allow for effective real-time collaboration for tasks such as 3D modelling. A major concern for integrating VE designer tools into the workplace is the fatigue often associated with such devices. Even if designers are twice as fast and accurate in a VE this is not particularly if they cannot use it continuously for more than half an hour. Thus, while the speed and accuracy findings of this experiment will be interesting and relevant to the workplace it is the extent of user fatigue that is perhaps the most interesting when considering such systems for practical use.
\subsection{Further research}
As stated above one of the most exciting possibilities for research in this area is supporting multiple users, either locally or remotely. By giving each user a virtual avatar and the ability to naturally modify the model displayed we can create an environment that is conducive to fast, collaborative prototyping and allows for interactive presentations.
More immediately however, further research can be done into effective ways to interact with the environment. This project, for environment interaction at least, mostly transfers the existing tools from the desktop application and makes them available in a VE. The much greater variety of interaction techniques offered by 6-DOF devices may allow for radically different interaction techniques.
\bibliographystyle{abbrv}
\bibliography{proposal}
\end{document}