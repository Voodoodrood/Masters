\documentclass{article}
\usepackage{float}
\usepackage{enumitem}
\usepackage{subfiles}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{tabularx}
\usepackage{url}
\usepackage{xcolor}
\usepackage{soul}
\setlist[description]{leftmargin=\parindent,labelindent=\parindent}
\makeatletter
\def\@copyrightspace{\relax}
\makeatother
\title{User Centred design process}
\begin{document}
\maketitle
\section{Overview of Methods}

User centred design (UCD) is a way of involving users in the design of artefacts\cite{abras2004user}. In our case: the design of a user interface for the creation of terrains in VR.
\newline\newline
UCD covers a number of techniques that can be implemented at various stages of the design\cite{abras2004user}. Because we are not starting from scratch but rather basing the VE interface on an existing desktop application we do not employ some of the UCD techniques typically used in the earlier stages of the design cycle\cite{McLoone2004}. However we use simulation and usability testing techniques in the prototype design stages. We also use a usability questionnaire for our final evaluation of the interface design.
\newline\newline 
By performing simulation and usability testing in the prototyping design stage we can address the majority of the usability issues before the final interface evaluation\cite{nielsen1990heuristic}. This ensures that the VE interface being compared to the existing desktop interface is robust and usable. This is necessary to ensure that a fair comparison is made between the VE and desktop applications and prevents a flaw in interface design affecting our results.
\newline\newline
The final evaluation and comparison of the interfaces is carried out by a group of students with experience using 3D content creation tools. We chose this group to be representative of target users\cite{Bowman2002}. By doing this we ensure our results are relevant to potential users.

\section{Initial Design concepts}
Since our interface is based on an existing desktop application we already have a basis for the initial design concept. However, the interface medium is different: a HMD and 6 DOF controllers as opposed to a desktop with mouse and keyboard. This means that certain interface elements need to be modified and new interaction metaphors need to be adopted.
\newline\newline
Many of our initial changes to design are based on findings in literature regarding the effective design of VR interfaces. Examples of this include menu design and performing actions at a distance. Using the literature as reference we are able to formulate a complete interface concept.
\newline\newline
\hl{Insert content here about initial designs and why we chose specific options over others}
\section{Paper Prototype}
We decided on an initial design and then created a paper prototype. This means that we have a physical artefact that could simulate a certain level of user interaction. We decided to use a paper prototype as it is fast and cheap to create. However, the fidelity of the prototype is limited.
\newline\newline
The paper prototype allows the user to interact with all UI elements that we plan to include in the VE interface. It also includes a number of user instructions to guide first time users through the program. Although the interface elements react to user input it was not feasible to have the terrain model itself to react. Thus users are required to imagine how the terrain changes based on verbal feedback.
\newline\newline
The prototype is constructed using a number of parts to represent various interface elements. The displayed terrain itself is represented by a flat sheet of paper on a table surface. This allows UI elements to be placed onto the terrain surface in approximation to the functionality of the VE. Users are asked to keep in mind that the terrain image was simply a representation of the VR display. A number of UI elements are represented by small cardboard tokens which can be placed onto the terrain or "view area".
\newline\newline
Although users do not wear an HMD while interacting with the prototype they are given the 6 DOF hand held devices that will be used with the final interface. This allows them to simulate the interaction they will have with the final interface. The devices are not tracked using software so users must state out loud what actions they were performing with the devices. An experimenter is then able to modify the terrain and interface representation in correspondence to the action taken. For example: The user points to a certain point and reports pressing the button assigned to creating a constraint. The experimenter then places the representation of a constraint at that point on the terrain.

\subsection{Evaluation}
The paper prototype is evaluated through a cognitive walkthrough method\cite{Bowman2002}. Users are asked to perform a number of basic actions with the help of textual instructions. This represents the typical first time user experience with the interface. Users report verbally on problems and insights they had with regards to the interface while performing these actions. Each experiment is video recorded for later review.
\newline\newline
We use this method of evaluation as it does not require our participants to be representative of our end users\cite{Bowman2002}. This makes it easier to recruit participants quickly. It also requires less time and expertise from participants than a heuristic evaluation would have. We decided that evaluating the paper prototype quickly and minimising the use of time resources is most suitable due to the low fidelity of the prototype. This allows us to efficiently trap the largest usability issues related to the prototype.
\newline\newline
\hl{Insert content here about specific user feedback}



\subsection{Changes to Design}
\hl{This section should probably be expanded or moved (and expanded)?}
\newline\newline
A number changes to the design of the interface were made based on the paper prototype evaluation.
\newline\newline
The way in which users interacted with the widget controlling the point constraints was clearly not intuitive and many users had difficulty with this. We therefore completely redesigned how this widget worked. The original concept preserved the concept of three independent axes that could be manipulated. However, this did not translate well into a 3D environment where there were six degrees of freedom. We therefore changed the widget to a one control for height and an second control that simultaneously defined the area of the constraint and the slope angle. The height control was restricted to movement along the y-axis but the area/angle control could freely be manipulated in 3D space. This simplified the control scheme and took advantage of the 6 DOF interaction devices.
\newline\newline
Another usability issue arose with regards to the menu design. Specifically users were required to use menu interfaces too often. Each step of a task often required the user to interact with a menu. To solve this problem we replaced a large part of the menu functionality with 3D props. This meant that users could simply pick up the desired tool from the environment rather than being forced to enter and exit a menu to select an action type.
\newpage
\section{High Fidelity prototype}

This prototype is created using Unity and is based off the paper prototype together with modifications resulting from the paper prototype evaluation. It allows real-time terrain interaction and supports the use of an Oculus rift HMD together with two  6 DOF Oculus touch controllers. It closely represents what the final interface is expected to look like. However, the terrain visual quality and realism is reduced and performance is slightly lower than expected for the final implementation.
\newline\newline
The prototype was created using Unity as it had better support for the Oculus Rift than native C++. This allows the prototype to be reliably created in a short amount of time. Integrating the HMD interface into the existing C++ application within the desired time period was unlikely due to the lack of support and researcher's lack of experience. As delays were encountered in other parts of the project we decided that the reliable and fast option should be taken even if this meant a loss of visual fidelity.
\newline\newline
Apart from the design changes the largest difference in this prototype from the paper prototype is the real time terrain interaction. This means the user receives instant feedback to their actions without going through an experimenter to explain what is happening. This is expected to greatly increase the speed at which the user is able to understand effective methods of interaction and reduce user frustration.


\subsection{Evaluation}
The High fidelity prototype is evaluated through a heuristic evaluation tool\cite{Bowman2002}. We use expert evaluation method with a set of heuristics designed for VEs\cite{Sutcliffe2004}. Heuristic evaluation is a cost effective method of usability evaluation\cite{nielsen1990heuristic}. Although any number of evaluators can be involved; three to five is the recommended number\cite{nielsen1990heuristic}.
\newline\newline
The method of evaluation is slightly different to the process for expert evaluation recommended by Nielsen\cite{Sutcliffe2004}. Specifically it involves an initial technology audit step which allows the evaluator to establish what the VR technology is capable of as a baseline. We can therefore identify usability issues that are an inherent property of the VR equipment. For example: there is no haptic feedback so users will not be able to feel objects in the VE. The technology audit aims to identify usability issues in four principle areas: Operation of user's presence, haptic feedback, interactive techniques and realistic graphics. User's presence refers to how the user is represented within the VE, Haptic feedback refers to the touch feedback provided by the VR technology, Interactive techniques refer to how the user interacts with objects in the VE and realistic graphics refer to the realism of the graphics the VE is able to provide.
\newline\newline
Prior to the evaluation the evaluation procedure is explained to the participants. This includes describing the technology audit, going over the heuristics and the way in which they are applied and how to rank the severity of issues. Users also complete the standard Oculus introduction to the touch controllers. This is the introductory experience any first time user goes through when setting up the Oculus Touch controllers. It is assumed as the bare baseline of proficiency when using them.
\newline\newline
After the technology audit is performed the user then familiarizes themselves with the application before carrying out a number of typical user tasks. While carrying out these tasks the user notes any issues encountered. Since users are wearing a HMD during this part of the experiment they are asked to verbally describe the issues. These descriptions are both video recorded and written down by an experimenter.
\newline\newline
After the tasks are completed the user leaves the VE. They then associate each issue with a heuristic. Where an issue is related to more than one heuristic the most applicable heuristic is chosen with a note made relating to the other applicable heuristics\cite{Sutcliffe2004}. Finally each issue is ranked by the severity of the impact it has on the assigned heuristic.
\newline\newline
\hl{List and explain heuristics here or elsewhere?}

\subsection{Changes to Design}

\hl{Will be filled in post evaluation}

\section{Final Design}

This is the final iteration of the interface. It was created in C++ on top of the existing desktop application. It incorporates all features and the visual fidelity of the desktop application. This allows us to directly compare the usability of the VE system against the desktop system in our final evaluation.
\newline\newline
As with the high fidelity prototype the interface supports the use of an Oculus rift HMD together with 2 Oculus touch controllers. \hl{Would like to say performance is equal on both systems but this remains to be seen.}

\subsection{Pilot Test}

Prior to the final evaluation of the VE and desktop applications a pilot test was conducted. This was done under the same experimental conditions and using the same methods as the final evaluation. The intention was to ensure the the experimental design was sound and that there were no issues with any of the hardware or software used or the instructions given to participants.

\hl{Will need to expand here in the event that changes are made due to the pilot test}

\subsection{Evaluation}

The evaluation of the final interface is carried out through summative evaluation\cite{Bowman2002}. Specifically the desktop and VE applications are compared statistically based off post-hoc questionnaire tools as well as measures of time taken to complete tasks and the accuracy of terrain models produced.
\newline\newline
For these evaluations we require that our participants are representative of our end users\cite{Bowman2002}. Therefore participants are drawn from Computer Science students who have worked with 3D modelling engines and Architecture students who have experience with 3D modelling. This ensures participants have a certain level of capability and intuition with respect to interacting with 3D modelling interfaces. Additionally participants take part in a training session before the evaluation session in order to familiarize themselves with the applications.  This is because previous research has shown that training has a significant effect on user performance in VEs\cite{Schultheis2012}.
\newline\newline
During the evaluation participants are asked to perform a number of tasks in the application. These include creating a terrain with set attributes as quickly as possible, reproducing a terrain based on an image as quickly as possible(In the VE the image was projected onto a surface users could look at) and creating a complete terrain of their choice. Each of these tasks is meant to allow the the speed, accuracy and usability of each system to be measured.
\newline\newline
Speed is measured by recording the time taken to complete a terrain with specific attributes. If the attributes are not correct the result is discarded. The required terrain attributes are such that each interface tool is used at least once.
\newline\newline
Accuracy is measured by asking participants to recreate a given terrain based on an image \hl{(or group fo images)}. Visual similarity is judged by a panel of human participants. This is opposed to using physical similarity which would be measured by computing volume differences. This is because visual accuracy is what would be desired in a typical terrain modelling use case rather than an exact physical accuracy.
\newline\newline
Usability is measured using the Post-Study System Usability Questionnaire (PSSUQ) which is a 19-item, 7 point scale questionnaire\cite{Lewis1995}. The PSSUQ allows us to collect results on overall satisfaction, system usefulness, information quality and interface quality.
\bibliographystyle{abbrv}
\bibliography{proposal}
\end{document}